{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HexaQuad4/style-/blob/main/english-colab-notebook/IndexTTS_Colab_EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKq-uSQXtXN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/index-tts/blob/feat/english-colab-notebook/IndexTTS_Colab_EN.ipynb)\n",
        "[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Wamp1re-Ai/index-tts/blob/feat/english-colab-notebook/IndexTTS_Colab_EN.ipynb)"
      ],
      "id": "oxKq-uSQXtXN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj4fZM7rXtXP"
      },
      "source": [
        "# IndexTTS: Zero-Shot Text-To-Speech on Colab/Kaggle (English UI)\n",
        "\n",
        "This notebook allows you to run the IndexTTS system in Google Colab or Kaggle. It will clone the repository, install dependencies, download models, and start the Gradio web UI. The UI will be in English.\n",
        "\n",
        "**Features:**\n",
        "- ✅ Works on both Google Colab and Kaggle\n",
        "- ✅ English UI with full internationalization support\n",
        "- ✅ Automatic environment detection and optimization\n",
        "- ✅ Fast dependency installation with UV package manager\n",
        "- ✅ Pre-configured model downloads from Hugging Face"
      ],
      "id": "Bj4fZM7rXtXP"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR1eQO9JXtXQ",
        "outputId": "7a336a2c-1209-4d3a-9e46-5ce6944bb773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment detected:\n",
            "- Google Colab: True\n",
            "- Kaggle: True\n",
            "Cloning into 'index-tts'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 557 (delta 127), reused 126 (delta 126), pack-reused 420 (from 1)\u001b[K\n",
            "Receiving objects: 100% (557/557), 1.84 MiB | 14.62 MiB/s, done.\n",
            "Resolving deltas: 100% (324/324), done.\n",
            "/content/index-tts\n",
            "Branch 'feat/english-colab-notebook' set up to track remote branch 'feat/english-colab-notebook' from 'origin'.\n",
            "Switched to a new branch 'feat/english-colab-notebook'\n",
            "total 212\n",
            "drwxr-xr-x 8 root root  4096 Oct  7 15:54 .\n",
            "drwxr-xr-x 1 root root  4096 Oct  7 15:54 ..\n",
            "drwxr-xr-x 2 root root  4096 Oct  7 15:54 assets\n",
            "drwxr-xr-x 2 root root  4096 Oct  7 15:54 checkpoints\n",
            "-rw-r--r-- 1 root root  2212 Oct  7 15:54 DISCLAIMER\n",
            "-rw-r--r-- 1 root root  5804 Oct  7 15:54 ENGLISH_SUPPORT_SUMMARY.md\n",
            "drwxr-xr-x 8 root root  4096 Oct  7 15:54 .git\n",
            "-rw-r--r-- 1 root root   149 Oct  7 15:54 .gitignore\n",
            "-rw-r--r-- 1 root root 11689 Oct  7 15:54 INDEX_MODEL_LICENSE\n",
            "drwxr-xr-x 6 root root  4096 Oct  7 15:54 indextts\n",
            "-rw-r--r-- 1 root root 18604 Oct  7 15:54 IndexTTS_Colab_EN.ipynb\n",
            "-rw-r--r-- 1 root root 18224 Oct  7 15:54 IndexTTS_Kaggle_EN.ipynb\n",
            "-rw-r--r-- 1 root root 17979 Oct  7 15:54 IndexTTS_Kaggle_EN_ngrok.ipynb\n",
            "-rw-r--r-- 1 root root 11356 Oct  7 15:54 LICENSE\n",
            "-rw-r--r-- 1 root root    65 Oct  7 15:54 MANIFEST.in\n",
            "-rw-r--r-- 1 root root 13773 Oct  7 15:54 README.md\n",
            "-rw-r--r-- 1 root root   411 Oct  7 15:54 requirements.txt\n",
            "-rw-r--r-- 1 root root  1444 Oct  7 15:54 setup.py\n",
            "-rw-r--r-- 1 root root  6310 Oct  7 15:54 setup_tunnel.py\n",
            "-rw-r--r-- 1 root root  3587 Oct  7 15:54 test_english_ui.py\n",
            "drwxr-xr-x 2 root root  4096 Oct  7 15:54 tests\n",
            "-rw-r--r-- 1 root root  5002 Oct  7 15:54 test_tunnel.py\n",
            "drwxr-xr-x 3 root root  4096 Oct  7 15:54 tools\n",
            "-rw-r--r-- 1 root root  5864 Oct  7 15:54 TUNNEL_SETUP_GUIDE.md\n",
            "-rw-r--r-- 1 root root 22186 Oct  7 15:54 webui.py\n"
          ]
        }
      ],
      "source": [
        "# Environment Detection and Setup\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Detect environment\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "IN_KAGGLE = 'kaggle_secrets' in sys.modules or os.path.exists('/kaggle')\n",
        "\n",
        "print(f\"Environment detected:\")\n",
        "print(f\"- Google Colab: {IN_COLAB}\")\n",
        "print(f\"- Kaggle: {IN_KAGGLE}\")\n",
        "\n",
        "# Clone the IndexTTS repository\n",
        "!git clone https://github.com/Wamp1re-Ai/index-tts.git\n",
        "%cd index-tts\n",
        "\n",
        "# Switch to the English support branch\n",
        "!git checkout feat/english-colab-notebook\n",
        "\n",
        "!ls -la"
      ],
      "id": "hR1eQO9JXtXQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtnINZd1XtXS"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "This step installs `ffmpeg` (required for audio processing) and all the Python packages listed in `requirements.txt`. The installation is optimized for both Colab and Kaggle environments."
      ],
      "id": "XtnINZd1XtXS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpGCYgiFXtXT",
        "outputId": "957ced2d-2bae-4922-9f0c-7bf3547a3645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [3 InRelea\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,065 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,811 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,275 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,336 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,750 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,415 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,582 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,922 kB]\n",
            "Fetched 30.6 MB in 3s (9,684 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Collecting uv\n",
            "  Downloading uv-0.8.24-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.8.24-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.2/21.2 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.8.24\n",
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 2.18s\u001b[0m\u001b[0m\n",
            "\u001b[2K  \u001b[31m×\u001b[0m Failed to build `llvmlite==0.41.1`\n",
            "\u001b[31m  ├─▶ \u001b[0mThe build backend returned an error\n",
            "\u001b[31m  ╰─▶ \u001b[0mCall to `setuptools.build_meta:__legacy__.build_wheel` failed (exit\n",
            "\u001b[31m      \u001b[0mstatus: 1)\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stdout]\u001b[39m\n",
            "\u001b[31m      \u001b[0mrunning bdist_wheel\n",
            "\u001b[31m      \u001b[0m/root/.cache/uv/builds-v0/.tmpllOspT/bin/python\n",
            "\u001b[31m      \u001b[0m/root/.cache/uv/sdists-v9/pypi/llvmlite/0.41.1/SGfNVg34H81blDmb4p01G/src/ffi/build.py\n",
            "\u001b[31m      \u001b[0mLLVM version...\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n",
            "\u001b[31m      \u001b[0mTraceback (most recent call last):\n",
            "\u001b[31m      \u001b[0m  File\n",
            "\u001b[31m      \u001b[0m\"/root/.cache/uv/sdists-v9/pypi/llvmlite/0.41.1/SGfNVg34H81blDmb4p01G/src/ffi/build.py\",\n",
            "\u001b[31m      \u001b[0mline 228, in <module>\n",
            "\u001b[31m      \u001b[0m    main()\n",
            "\u001b[31m      \u001b[0m  File\n",
            "\u001b[31m      \u001b[0m\"/root/.cache/uv/sdists-v9/pypi/llvmlite/0.41.1/SGfNVg34H81blDmb4p01G/src/ffi/build.py\",\n",
            "\u001b[31m      \u001b[0mline 218, in main\n",
            "\u001b[31m      \u001b[0m    main_posix('linux', '.so')\n",
            "\u001b[31m      \u001b[0m  File\n",
            "\u001b[31m      \u001b[0m\"/root/.cache/uv/sdists-v9/pypi/llvmlite/0.41.1/SGfNVg34H81blDmb4p01G/src/ffi/build.py\",\n",
            "\u001b[31m      \u001b[0mline 135, in main_posix\n",
            "\u001b[31m      \u001b[0m    raise RuntimeError(msg) from None\n",
            "\u001b[31m      \u001b[0mRuntimeError: Could not find a `llvm-config` binary. There\n",
            "\u001b[31m      \u001b[0mare a number of reasons this could occur, please see:\n",
            "\u001b[31m      \u001b[0mhttps://llvmlite.readthedocs.io/en/latest/admin-guide/install.html#using-pip\n",
            "\u001b[31m      \u001b[0mfor help.\n",
            "\u001b[31m      \u001b[0merror: command '/root/.cache/uv/builds-v0/.tmpllOspT/bin/python' failed\n",
            "\u001b[31m      \u001b[0mwith exit code 1\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n",
            "\u001b[31m      \u001b[0menvironment.\n",
            "\u001b[36m  help: \u001b[0m`\u001b[36mllvmlite\u001b[39m` (\u001b[36mv0.41.1\u001b[39m) was included because `\u001b[36mnumba\u001b[39m` (\u001b[36mv0.58.1\u001b[39m) depends\n",
            "        on `\u001b[36mllvmlite\u001b[39m`\n",
            "✅ Successfully installed requirements.txt\n",
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mwetextprocessing==1.0.4.1                                                     \u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install system dependencies\n",
        "if IN_COLAB or IN_KAGGLE:\n",
        "    !apt-get update && apt-get install -y ffmpeg\n",
        "else:\n",
        "    print(\"Please ensure ffmpeg is installed on your system\")\n",
        "\n",
        "# Install uv for faster package installation\n",
        "!pip install uv\n",
        "\n",
        "# Install Python dependencies using uv\n",
        "# Note: WeTextProcessing is required for text normalization\n",
        "# pynini might have installation issues on some platforms\n",
        "try:\n",
        "    !uv pip install -r requirements.txt --system\n",
        "    print(\"✅ Successfully installed requirements.txt\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error installing requirements.txt: {e}\")\n",
        "    print(\"Trying alternative installation method...\")\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "# Install WeTextProcessing separately for better error handling\n",
        "try:\n",
        "    !uv pip install WeTextProcessing --system\n",
        "    print(\"✅ Successfully installed WeTextProcessing\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error installing WeTextProcessing: {e}\")\n",
        "    print(\"Trying with pip...\")\n",
        "    !pip install WeTextProcessing"
      ],
      "id": "wpGCYgiFXtXT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggv5uQDjXtXT"
      },
      "source": [
        "## Download Models\n",
        "\n",
        "The following commands will download the necessary model checkpoints from Hugging Face. This works on both Colab and Kaggle environments.\n",
        "\n",
        "**Note:** The models are approximately 2GB in total. Download time depends on your internet connection."
      ],
      "id": "Ggv5uQDjXtXT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMm-hkWNXtXU"
      },
      "outputs": [],
      "source": [
        "# Ensure huggingface_hub is installed\n",
        "!pip install huggingface_hub\n",
        "\n",
        "# Download models using huggingface-cli\n",
        "print(\"📥 Downloading IndexTTS models from Hugging Face...\")\n",
        "print(\"This may take a few minutes depending on your connection.\")\n",
        "\n",
        "!huggingface-cli download IndexTeam/Index-TTS \\\n",
        "    bigvgan_discriminator.pth \\\n",
        "    bigvgan_generator.pth \\\n",
        "    bpe.model \\\n",
        "    dvae.pth \\\n",
        "    gpt.pth \\\n",
        "    unigram_12000.vocab \\\n",
        "    --repo-type model \\\n",
        "    --local-dir checkpoints \\\n",
        "    --local-dir-use-symlinks False\n",
        "\n",
        "print(\"✅ Model download completed!\")\n",
        "\n",
        "# Verify checkpoint files\n",
        "print(\"\\n📁 Verifying downloaded files:\")\n",
        "!ls -l checkpoints/\n",
        "\n",
        "# Check if all required files are present\n",
        "import os\n",
        "required_files = [\n",
        "    'bigvgan_discriminator.pth',\n",
        "    'bigvgan_generator.pth',\n",
        "    'bpe.model',\n",
        "    'dvae.pth',\n",
        "    'gpt.pth',\n",
        "    'unigram_12000.vocab',\n",
        "    'config.yaml'\n",
        "]\n",
        "\n",
        "missing_files = []\n",
        "for file in required_files:\n",
        "    if not os.path.exists(f'checkpoints/{file}'):\n",
        "        missing_files.append(file)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"⚠️  Missing files: {missing_files}\")\n",
        "else:\n",
        "    print(\"✅ All required model files are present!\")"
      ],
      "id": "xMm-hkWNXtXU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgahBxSyXtXU"
      },
      "source": [
        "## Run the Gradio Web UI with Public Access\n",
        "\n",
        "This will start the Gradio web interface with English UI and set up public URL access using Cloudflare tunnels.\n",
        "\n",
        "### 🌐 Public URL Options:\n",
        "\n",
        "**For Colab:**\n",
        "- 🔗 **Primary**: Colab's built-in public URL (ending with `gradio.live`)\n",
        "- 🌍 **Backup**: Cloudflare tunnel URL (ending with `trycloudflare.com`)\n",
        "\n",
        "**For Kaggle:**\n",
        "- 🌍 **Primary**: Cloudflare tunnel URL (ending with `trycloudflare.com`)\n",
        "- 📱 **Fallback**: Kaggle's output panel\n",
        "\n",
        "### ✨ Features:\n",
        "- ✅ **English UI** with full internationalization support\n",
        "- ✅ **Public URLs** accessible from anywhere\n",
        "- ✅ **No registration required** for Cloudflare tunnels\n",
        "- ✅ **Automatic setup** - just run the cell below\n",
        "\n",
        "### 🔒 Security Note:\n",
        "The public URLs are temporary and will expire when the notebook session ends. Do not share sensitive information through these interfaces."
      ],
      "id": "bgahBxSyXtXU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeDKoQDlXtXV"
      },
      "outputs": [],
      "source": [
        "# Setup public tunnel access with ngrok (primary) and Cloudflare (fallback)\n",
        "import os\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Set environment variables for optimal performance\n",
        "os.environ['GRADIO_SERVER_NAME'] = '0.0.0.0'\n",
        "os.environ['GRADIO_SERVER_PORT'] = '7860'\n",
        "\n",
        "# Ensure English language is set\n",
        "os.environ['LANG'] = 'en_US.UTF-8'\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
        "\n",
        "print(\"🚀 Starting IndexTTS Web UI with English interface...\")\n",
        "print(\"🌐 Setting up reliable public URL access...\")\n",
        "print(\"🎯 Using ngrok (primary) + Cloudflare (fallback) for maximum reliability\")\n",
        "\n",
        "# Setup ngrok tunnel (more reliable)\n",
        "def setup_ngrok_tunnel():\n",
        "    try:\n",
        "        # Install ngrok\n",
        "        print(\"📦 Installing ngrok for reliable public URL access...\")\n",
        "        !wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "        !tar xzf ngrok-v3-stable-linux-amd64.tgz\n",
        "        !mv ngrok /usr/local/bin/ngrok\n",
        "        !chmod +x /usr/local/bin/ngrok\n",
        "        print(\"✅ ngrok installed successfully\")\n",
        "\n",
        "        # Start ngrok tunnel\n",
        "        def start_ngrok():\n",
        "            time.sleep(8)  # Wait for Gradio to start\n",
        "            try:\n",
        "                print(\"\\n🚀 Starting ngrok tunnel...\")\n",
        "                print(\"⏳ This usually takes 10-20 seconds...\")\n",
        "\n",
        "                process = subprocess.Popen([\n",
        "                    'ngrok', 'http', '7860', '--log=stdout'\n",
        "                ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)\n",
        "\n",
        "                # Monitor output for tunnel URL\n",
        "                start_time = time.time()\n",
        "                timeout = 45\n",
        "\n",
        "                while time.time() - start_time < timeout:\n",
        "                    line = process.stdout.readline()\n",
        "                    if line:\n",
        "                        line = line.strip()\n",
        "                        print(f\"[ngrok] {line}\")\n",
        "\n",
        "                        # Look for ngrok URL\n",
        "                        if 'url=' in line and 'ngrok' in line:\n",
        "                            parts = line.split('url=')\n",
        "                            if len(parts) > 1:\n",
        "                                url = parts[1].split()[0]\n",
        "                                if url.startswith('http') and 'ngrok' in url:\n",
        "                                    print(f\"\\n🎉 SUCCESS! ngrok tunnel is ready!\")\n",
        "                                    print(f\"🔗 ngrok URL: {url}\")\n",
        "                                    print(f\"🌍 Share this URL with anyone: {url}\")\n",
        "                                    print(f\"📱 Your IndexTTS is now publicly accessible!\")\n",
        "                                    print(f\"✨ ngrok is more reliable than Cloudflare tunnels\\n\")\n",
        "                                    return\n",
        "\n",
        "                        # Alternative format\n",
        "                        if 'Forwarding' in line and 'ngrok' in line:\n",
        "                            parts = line.split()\n",
        "                            for part in parts:\n",
        "                                if part.startswith('http') and 'ngrok' in part:\n",
        "                                    print(f\"\\n🎉 SUCCESS! ngrok tunnel is ready!\")\n",
        "                                    print(f\"🔗 ngrok URL: {part}\")\n",
        "                                    print(f\"🌍 Share this URL with anyone: {part}\")\n",
        "                                    print(f\"📱 Your IndexTTS is now publicly accessible!\\n\")\n",
        "                                    return\n",
        "\n",
        "                    if process.poll() is not None:\n",
        "                        break\n",
        "\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "                print(\"⏰ ngrok tunnel setup timeout\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  ngrok tunnel error: {e}\")\n",
        "\n",
        "        # Start ngrok in background\n",
        "        ngrok_thread = threading.Thread(target=start_ngrok, daemon=True)\n",
        "        ngrok_thread.start()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  ngrok setup failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Setup Cloudflare as fallback\n",
        "def setup_cloudflare_fallback():\n",
        "    try:\n",
        "        print(\"\\n🔄 Also setting up Cloudflare tunnel as backup...\")\n",
        "        !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "        !dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "        def start_cloudflare():\n",
        "            time.sleep(15)  # Wait a bit longer\n",
        "            try:\n",
        "                print(\"\\n🌐 Starting Cloudflare tunnel as backup...\")\n",
        "                process = subprocess.Popen([\n",
        "                    'cloudflared', 'tunnel', '--url', 'http://localhost:7860'\n",
        "                ], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "\n",
        "                for line in iter(process.stdout.readline, ''):\n",
        "                    line = line.strip()\n",
        "                    if line and 'trycloudflare.com' in line:\n",
        "                        words = line.split()\n",
        "                        for word in words:\n",
        "                            if word.startswith('http') and 'trycloudflare.com' in word:\n",
        "                                print(f\"\\n🔗 Backup Cloudflare URL: {word}\")\n",
        "                                return\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  Cloudflare backup failed: {e}\")\n",
        "\n",
        "        cf_thread = threading.Thread(target=start_cloudflare, daemon=True)\n",
        "        cf_thread.start()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Cloudflare backup setup failed: {e}\")\n",
        "\n",
        "# Setup tunnels\n",
        "ngrok_success = setup_ngrok_tunnel()\n",
        "setup_cloudflare_fallback()  # Always setup as backup\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"🔗 Colab will also provide a gradio.live URL\")\n",
        "    if ngrok_success:\n",
        "        print(\"🌐 ngrok tunnel will provide the most reliable public URL (see above)\")\n",
        "        print(\"🔄 Cloudflare tunnel available as backup\")\n",
        "elif IN_KAGGLE:\n",
        "    if ngrok_success:\n",
        "        print(\"🌐 Public access via ngrok tunnel (see above)\")\n",
        "    else:\n",
        "        print(\"🔗 Interface will be available in Kaggle's output panel\")\n",
        "\n",
        "print(\"\\n🚀 Launching IndexTTS...\")\n",
        "print(\"⏳ Please wait for the ngrok URL to appear above...\")\n",
        "print(\"💡 ngrok URLs are more reliable than Cloudflare tunnels\")\n",
        "\n",
        "# Run the Web UI with public access\n",
        "!python webui.py --host 0.0.0.0 --port 7860"
      ],
      "id": "EeDKoQDlXtXV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBcVXQI1XtXW"
      },
      "source": [
        "---\n",
        "## (Optional) Command-Line Interface (CLI) Usage\n",
        "\n",
        "You can also use IndexTTS via its command-line interface.\n",
        "First, you'll need a reference audio. You can upload one to your Colab environment or use a sample. Let's create a dummy reference for demonstration if you don't have one.\n",
        "\n",
        "**Note:** You'll need to have a `reference_voice.wav` file in the main `index-tts` directory for the example below to work, or modify the path.\n",
        "You might need to stop the Web UI cell above to run this."
      ],
      "id": "eBcVXQI1XtXW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N382GmBXtXW"
      },
      "outputs": [],
      "source": [
        "# (Example) Create a dummy reference voice file if you don't have one\n",
        "# This is just a placeholder. Replace with your actual reference audio.\n",
        "# import numpy as np\n",
        "# import soundfile as sf\n",
        "# samplerate = 22050\n",
        "# duration = 1\n",
        "# frequency = 440\n",
        "# t = np.linspace(0., duration, int(samplerate * duration), endpoint=False)\n",
        "# data = 0.5 * np.sin(2. * np.pi * frequency * t)\n",
        "# sf.write('reference_voice.wav', data, samplerate)\n",
        "\n",
        "# Install IndexTTS as a package for CLI usage\n",
        "!pip install -e .\n",
        "\n",
        "# Run CLI inference (make sure 'reference_voice.wav' exists or change path)\n",
        "# !indextts \"Hello, this is a test of the IndexTTS command line interface.\" \\\n",
        "#   --voice reference_voice.wav \\\n",
        "#   --model_dir checkpoints \\\n",
        "#   --config checkpoints/config.yaml \\\n",
        "#   --output output_cli.wav\n",
        "\n",
        "# print(\"If successful, output_cli.wav should be generated.\")\n",
        "# You can then listen to it or download it from the file browser on the left."
      ],
      "id": "5N382GmBXtXW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaBnv88cXtXW"
      },
      "source": [
        "---\n",
        "## (Optional) Python Script Usage\n",
        "\n",
        "You can also use IndexTTS directly in Python.\n",
        "\n",
        "**Note:** You might need to stop the Web UI cell above to run this."
      ],
      "id": "PaBnv88cXtXW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTqq8h8BXtXX"
      },
      "outputs": [],
      "source": [
        "# from indextts.infer import IndexTTS\n",
        "\n",
        "# # Ensure you have a reference voice, e.g., 'reference_voice.wav'\n",
        "# # This assumes 'reference_voice.wav' is in the current directory (index-tts)\n",
        "# reference_audio_path = \"reference_voice.wav\"\n",
        "# text_to_speak = \"This is a sample sentence generated using the IndexTTS Python interface.\"\n",
        "# output_file_path = \"output_script.wav\"\n",
        "\n",
        "# if 'tts' not in locals(): # Avoid re-initializing if already done\n",
        "#   tts = IndexTTS(model_dir=\"checkpoints\",cfg_path=\"checkpoints/config.yaml\")\n",
        "\n",
        "# # Check if reference_voice.wav exists, if not, skip inference\n",
        "# import os\n",
        "# if os.path.exists(reference_audio_path):\n",
        "#   tts.infer(reference_audio_path, text_to_speak, output_file_path)\n",
        "#   print(f\"Generated audio saved to {output_file_path}\")\n",
        "#   # You can play/download this file from Colab's file browser\n",
        "# else:\n",
        "#   print(f\"Reference audio {reference_audio_path} not found. Skipping script inference demo.\")"
      ],
      "id": "uTqq8h8BXtXX"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}